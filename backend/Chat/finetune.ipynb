{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Fine Tuning Open AI's GPT2\n","## Introduction\n","* As a part of leveraging the power of large language models, we have also attempted fine tuning a language model to act as our application's chatbot assistant.\n","\n","    We have used the following libraries for fine tuning: \n","    1. `transformers[torch]`\n","    2. `pytorch`\n","    3. `shutil`\n","\n","* Using these libraries, we have managed to fine tune openAI's `GPT2` Model on a custom made dataset containing 100 question answer pairs. The dataset has been explained more in detail in later parts of this notebook\n","* The following models were also tested during our finetuning process: `Bert-large`and `bert`, unfortunalely we didn't consider them due to unsatisfactory results/dependency issues. "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T14:40:03.070301Z","iopub.status.busy":"2024-04-01T14:40:03.069436Z","iopub.status.idle":"2024-04-01T14:40:03.099454Z","shell.execute_reply":"2024-04-01T14:40:03.098707Z","shell.execute_reply.started":"2024-04-01T14:40:03.070267Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Copied\n"]}],"source":["import shutil\n","src_path = r\"/kaggle/input/sign-language-text/Sign Language info dataset.txt\"\n","dst_path = r\"/kaggle/working/\"\n","shutil.copy(src_path, dst_path)\n","print('Copied')"]},{"cell_type":"markdown","metadata":{},"source":["## About the Dataset\n","\n","* The dataset has been custom made by team tekken, we have collected around 100 different question answer pairs that have been formatted. Each answer is around 50-60 words.A Sample from the dataset: \n","\n","    **[Q] What is ASL? \\newline**\n","\n","    **[A] ASL stands for American Sign Language, which is a natural language primarily used by Deaf communities in the United States and Anglophone Canada.**\n","\n","* The samples range from a wide range of topics such as American Sign Language, Indian Sign Language, british sign language, significance of sign language. Questions related to `Saradhi.AI` (our application) have also been included.\n","\n","## Model Configuration\n","\n","* The model has been loaded using the `GPT2LMHeadModel.from_pretrained()` method, along with it's tokenizer usign the `GPT2Tokenizer.from_pretrained()`. The parameters used for finetuning are as follows: \n","\n","    `num_train_epochs=100,\n","    per_device_train_batch_size=8,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    logging_dir=\"./logs\",`"]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-01T14:56:49.901876Z","iopub.status.busy":"2024-04-01T14:56:49.901138Z","iopub.status.idle":"2024-04-01T14:59:01.139734Z","shell.execute_reply":"2024-04-01T14:59:01.138571Z","shell.execute_reply.started":"2024-04-01T14:56:49.901843Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 01:52, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Generated Text:\n","who created Saradhi AI), a sign language interpreter for programmers, that was developed to make sign language accessible to everyone.\n","\n","\n","[Q] How did Saradhi AI facilitate sign language learning?\n","[A] Saradhi AI facilitated sign language learning through informative courses on learning sign language, facilitated by a chatbot.\n","\n","\n","[Q] What is the significance of Martha's Vineyard Sign Language (MVSL) in the history of ASL?\n","[A] MV\n"]}],"source":["# Install necessary libraries\n","# !pip install transformers\n","# ! pip install torch\n","import torch\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n","\n","# Load pre-trained GPT-2 model and tokenizer\n","model_name = \"gpt2\"\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","# Load your text file\n","file_path = \"/kaggle/working/Sign Language info dataset.txt\"\n","\n","# Create a dataset from the text file\n","dataset = TextDataset(tokenizer=tokenizer, file_path=file_path, block_size=128)\n","\n","# Define data collator for language modeling\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./finetuned_model\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=100,\n","    per_device_train_batch_size=8,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    logging_dir=\"./logs\",\n",")\n","\n","# Create Trainer instance\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset,\n",")\n","\n","# Fine-tune the model\n","trainer.train()\n","\n","# Save the fine-tuned model\n","model_path = \"/kaggle/working/finetuned_gpt2_model.bin\"\n","model.save_pretrained(model_path)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Inference from the finetuned model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T15:00:36.793159Z","iopub.status.busy":"2024-04-01T15:00:36.792500Z","iopub.status.idle":"2024-04-01T15:00:40.318428Z","shell.execute_reply":"2024-04-01T15:00:40.316580Z","shell.execute_reply.started":"2024-04-01T15:00:36.793128Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Generated Text:\n","[Q] Who created Saradhi AI?\n","[A] Saradhi AI was created by a team passionate about making sign language accessible to everyone, known as Team Tekken.\n","\n","\n","[Q] What is the purpose of the real-time sign language translation feature in Saradhi AI?\n","[A] The real-time sign language translation feature in Saradhi AI converts sign language gestures captured by the device's camera into understandable text, facilitating communication.\n","\n","\n","[Q\n"]}],"source":["# Perform inference\n","prompt_text = \"[Q] Who created Saradhi AI?\"\n","input_ids = tokenizer.encode(prompt_text, return_tensors=\"pt\")\n","\n","# Move input tensor to the same device as the model\n","# Move model to the same device as the input tensor\n","model.to(input_ids.device)\n","\n","# Perform inference\n","output = model.generate(input_ids, max_length=100, num_return_sequences=1, temperature=0.1)\n","\n","# Decode and print the output\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","print(\"Generated Text:\")\n","print(generated_text)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-01T14:55:28.809105Z","iopub.status.busy":"2024-04-01T14:55:28.808746Z","iopub.status.idle":"2024-04-01T14:55:29.377139Z","shell.execute_reply":"2024-04-01T14:55:29.375976Z","shell.execute_reply.started":"2024-04-01T14:55:28.809077Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), '/kaggle/working/model.pth')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4702422,"sourceId":7988267,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
